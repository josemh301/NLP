{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5a316c",
   "metadata": {},
   "source": [
    "# Analysis of Disaster-Related Terms in Social Media Data using NER\n",
    "\n",
    "**Objectives**:\n",
    "1. Apply Named Entity Recognition (NER) to identify disaster types and related terms.\n",
    "1. Analyze and compare the frequency of different disaster terms to gauge public awareness and concerns.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. Load the dataset from `'tweets.csv'`.\n",
    "1. Preprocessing and data cleaning\n",
    "1. Utilize the `spacy` library to lemmatize the text and filter it based on parts of speech.\n",
    "1. Analyze the data to identify the most common disaster keywords.\n",
    "1. Extract and count terms related to the top five disaster keywords.\n",
    "1. Organize and display the findings for each disaster type, showing the most common related terms and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f534fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Update preprocess_text function to use remove_emojis\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove emojis\n",
    "    text = remove_emojis(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98133ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fec2814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pos(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.text for token in doc if token.pos_ in ['NOUN', 'VERB', 'ADJ']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7243b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "disaster_counts = Counter(data['keyword'])\n",
    "top_5_disasters = disaster_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80e188bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_terms(disaster_type):\n",
    "    filtered_data = data[data['keyword'] == disaster_type]\n",
    "    terms = []\n",
    "    for text in filtered_data['text']:\n",
    "        text = preprocess_text(text)\n",
    "        text = lemmatize_text(text)\n",
    "        text = filter_pos(text)\n",
    "        terms.extend(text.split())\n",
    "    term_counts = Counter(terms)\n",
    "    return term_counts\n",
    "\n",
    "disaster_term_counts = {disaster: get_related_terms(disaster) for disaster, _ in top_5_disasters}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55bdbc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disaster Type: thunderstorm\n",
      "                Term  Frequency\n",
      "7       thunderstorm         34\n",
      "11           warning         27\n",
      "29           weather         23\n",
      "97           include         15\n",
      "107           severe         10\n",
      "171               pm         10\n",
      "167         continue         10\n",
      "18      Thunderstorm         10\n",
      "187  nwsseveretstorm          8\n",
      "20            affect          8\n",
      "\n",
      "\n",
      "Disaster Type: flattened\n",
      "         Term  Frequency\n",
      "2     flatten         65\n",
      "34       home         13\n",
      "33    tornado         13\n",
      "108      kill         12\n",
      "104    prayer         12\n",
      "105    closet         12\n",
      "109      many         12\n",
      "106   survive         12\n",
      "107  powerful         12\n",
      "25       have          6\n",
      "\n",
      "\n",
      "Disaster Type: mass%20murder\n",
      "        Term  Frequency\n",
      "3       mass         43\n",
      "6     murder         42\n",
      "0         be         16\n",
      "150    thank          7\n",
      "24    people          6\n",
      "42       use          5\n",
      "228     want          5\n",
      "32    regime          5\n",
      "51      mean          5\n",
      "28   iranian          5\n",
      "\n",
      "\n",
      "Disaster Type: stretcher\n",
      "          Term  Frequency\n",
      "4    stretcher         47\n",
      "34  helicopter         11\n",
      "37         get         10\n",
      "29         man          9\n",
      "32       start          8\n",
      "33      rescue          6\n",
      "95         put          6\n",
      "15        play          5\n",
      "39       carry          5\n",
      "21          be          5\n",
      "\n",
      "\n",
      "Disaster Type: drown\n",
      "      Term  Frequency\n",
      "3    drown         62\n",
      "13      go          8\n",
      "62    come          7\n",
      "78    time          6\n",
      "99    have          5\n",
      "63     try          5\n",
      "56     get          5\n",
      "23    feel          4\n",
      "9      tie          4\n",
      "30  sorrow          4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each disaster type and its DataFrame to print the terms and frequencies\n",
    "for disaster, df in disaster_dataframes.items():\n",
    "    print(f\"Disaster Type: {disaster}\")\n",
    "    print(df.sort_values(by='Frequency', ascending=False).head(10))  # Show top 10 terms for each disaster\n",
    "    print('\\n')  # Print a newline to separate results for different disaster types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
